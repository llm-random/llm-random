
parent: configs/projected_dis/1ff/common.yaml
md5_parent_hash: 857e8482d095f33083fee68ab10421b4
time: 0-04:00:00
# n_gpus: 2 #dev
n_gpus: 1
cpus_per_gpu: 16

params:
  name: "PD"
  tags: ["projected_dis", "1ff", "compression", "dm256", "half_var"]

  dmodel: 256
  dff: 256
  projected_dmodel: 512
  projected_dff: 512
  # ^n_steps: [6168, 8812] # same as dmodel
  n_steps: 6168 # same as dmodel
  # ^learning_rate: [0.00025, 0.0005, 0.001, 0.002, 0.004, 0.008]
  learning_rate: 0.001
  
  attention_mode: projected_vanilla
  ff_mode: projected_vanilla

  ^projection_init_type: [half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var, half_var]
  # ^projection_init_type: [half, orthogonal]
 
  projected_distillation: True
  # projected_weights_path: /net/pr2/projects/plgrid/plggllmeffi/plgmstefaniak/llm_random_cemetery/PD_2025-01-24_18-16-36/None/1171839/19545.pt # trapez
  projected_weights_path: /net/pr2/projects/plgrid/plggllmeffi/plgmstefaniak/llm_random_cemetery/PD_2025-02-06_15-04-30/None/1191645/19545.pt # cosine

  # fsdp_use_orig_params: True
  # fsdp_enabled: True
  # fsdp_modules_to_wrap: "EmbeddingLayer,PredictionHead,TransformerBlock"
  # fsdp_selective_precision_modules: "AttentionMechanism,MoeGating,RoPE"






