parent: configs/baselines/gpt/expert_choice/base.yaml
md5_parent_hash: 1e26b36309694f6144e476f783aaded0
time: 0-24:00:00

params:
  name: weightless_tune_fixed_base
  activation_type: silu
  save_weights_interval: 0
  #^mixed_precision: [True, False]
  mixed_precision: True
  #^moe_detach_gate: [False, True]
  moe_detach_gate: False
  ^ff_mode: [expert_choice]
  expansion_rate: 8
  granularity: 1
  ^get_router_values_from: [gate_weight, weights]
  moe_inner_expert: ff_gated
  ^learning_rate: [0.002, 0.001, 0.0005, 0.0002, 0.0001]
  flash_attention: False
  layer_norm_in_expert_choice: False

  n_steps: 80_000
  final_lr_step: 80_000
  scheduler: cosine
  lr_warmup_steps: 800
  final_lr_fraction: 0.1

  batch_size: 256
  cutoff: 256

  loss_checkpoint_chungs: 4

  mixed_precision_dtype: bfloat16
  #fsdp_enabled: true
  #fsdp_modules_to_wrap: "EmbeddingLayer,PredictionHead,TransformerBlock"
  #activation_checkpointing_modules: "EmbeddingLayer,PredictionHead,TransformerBlock"
  #fsdp_selective_precision_modules: "AttentionMechanism,ExpertGating,RoPE,TokenGating,MoeGating"